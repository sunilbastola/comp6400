{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7f3b0cf-c609-4f2e-9287-165477f2a3c1",
   "metadata": {},
   "source": [
    "# Assignment - Intelligent Machines, Ethics and Law (COMP2400/6400)\n",
    "\n",
    "## Name: Sunil Bastola\n",
    "## Student Id: 48659851"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9815d6df-606b-42bd-a16f-beb112ff7e88",
   "metadata": {},
   "source": [
    "## Recidivism Risk Classification\n",
    "\n",
    "In this assignment, you will build a recidivism risk classification system using the COMPAS dataset.\n",
    "You will manually preprocess the data in Python, handle imbalanced classes, and implement both\n",
    "Logistic Regression (or other machine learning model covered in Week 10 to Week 12) and a simple Neural Network. \\\n",
    "You will then evaluate model performance and assess fairness across racial subgroups.\n",
    "\n",
    "This exercise is designed to:\n",
    "  - Familiarize you with data preprocessing and feature engineering.\n",
    "  - Expose you to handling class imbalance via oversampling.\n",
    "  - Build training and evaluating classification models.\n",
    "  - Critically examine model bias and fairness metrics.\n",
    "\n",
    "This task is graded out of 30 marks and contributes 30 marks toward the final unit assessment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec67fd4-2446-4233-9779-160c31443338",
   "metadata": {},
   "source": [
    "## COMPAS Dataset Description\n",
    "\n",
    "The COMPAS Recidivism dataset was first released by ProPublica in 2016 and contains data on over 7,000 criminal defendants from Broward County, Florida, assessed between 2013 and 2014. Key fields include demographic attributes (age, sex, race), offense history metrics (juvenile felony/misdemeanor/other counts, adult priors count), current charge details (degree and description), and COMPAS-generated risk assessments (decile score and qualitative risk category). Outcome labels capture general two-year recidivism (‘is_recid’) enabling classification and fairness analyses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e8ead8-c786-444e-b712-b54ffe188481",
   "metadata": {},
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ac81318-b40a-4cf1-b1f0-e932e52bd8ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pandas) (2.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d992201e-866d-42e0-a59e-a2d8f944a127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (1.6.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from scikit-learn) (2.1.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from scikit-learn) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from scikit-learn) (3.6.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7d28f65-2eac-4497-93fa-eb0ec625180c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (3.10.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: numpy>=1.23 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib) (2.1.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/sunil/Library/Python/3.10/lib/python/site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2297c05f-1149-4cda-87d4-4e043d26dc63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf20ff9-5a6a-44b1-8b6e-e5d90444d76b",
   "metadata": {},
   "source": [
    "## Task 1 (10 marks)\n",
    "TO DO:\n",
    "1. **(2 mark)** Load the dataset:\\\n",
    "   Read the COMPAS recidivism dataset using pandas.\n",
    "3. Clean the dataset:\n",
    "   Some of the feature columns in the dataset, such as jail admission/release dates and release case numbers, are outside the scope of the classification pipeline. So we need to clean the dataframe before modeling.\n",
    "   1. **(2 mark)** The column 'is_recid' can be 1 (recidivism within two years), 0 (no recidivism), or -1 (censored/invalid follow-up).\\\n",
    "      We need to **drop censored/invalid cases**.\n",
    "   2. **(2 marks)** COMPAS includes demographic and offense history features.\\\n",
    "      **Select the following key predictors** for classification: **sex, age, race**, number of prior juvenile felony offenses (**'juv_fel_count'**), number of prior juvenile misdemeanor offenses (**'juv_misd_count'**), number of other juvenile offenses (**'juv_other_count'**), total prior adult offenses (**'priors_count'**), and current charge severity (**'c_charge_degree'**).\\\n",
    "      **Drop any records missing these values**.\n",
    "3. **(2 marks)** Oversample the minority class in the training data, creating a balanced training set.\n",
    "4. **(2 marks)** Split data into training and test dataset (80/20 split)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb6231a-ca0d-48ed-88de-e0e02587950d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################\n",
    "# TODO: Complete this part\n",
    "##############################################\n",
    "# Load the data set \n",
    "df = pd.read_csv(\"cox-violent-parsed_filt.csv\")\n",
    "\n",
    "# Drop censored/invalid case in the dataframe ('is_recid' = -1).\n",
    "df = None\n",
    "\n",
    "# Select the key predictors\n",
    "features = []\n",
    "\n",
    "# Drop any records missing these values.\n",
    "df = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ab09e9-5a17-4d9d-922e-df17d8b415d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################\n",
    "# No TODO in this section — you do not need to modify this code. \n",
    "##############################################\n",
    "# Print the dataframe\n",
    "# Your dataframe should have 9 columns (8 feature columns and 1 label column 'is_recid')\n",
    "# remove duplicates:\n",
    "# One individual can have multiple violent charges, each recorded as a row. \n",
    "# In this assignment, we just drop the duplicates for simplicity.\n",
    "df = df.drop_duplicates()\n",
    "print (df)\n",
    "print (\"Filtered dataframe column and rows:\", df.shape)\n",
    "\n",
    "# Visualize the distribution information of race\n",
    "GroupedData=df.groupby('race').size()\n",
    "GroupedData.plot(kind='bar', figsize=(4,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82bddaed-8ca5-4789-a65e-4865fcd87932",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################\n",
    "# No TODO in this section — you do not need to modify this code. \n",
    "##############################################\n",
    "# 'is_recid' indicates whether there's recidivism within two years (1), or no recidivism (0).\n",
    "# This is what we would like to predict based on the dataset.\n",
    "# Let's visualize it. \n",
    "df[\"is_recid\"].value_counts().plot.pie()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f044fd16-0e91-4952-9add-edc51ae1de87",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################\n",
    "# TODO: Complete this part\n",
    "##############################################\n",
    "# From the visualization above, we can see there are more no-recidivism cases compared to cases of recidivism.\n",
    "# This imbalanced dataset is problematic for training a model.\n",
    "# To handle imbalanced dataset in this assginment, we can over-sample the minority class.\n",
    "# Name the oversampled df as \"df_bal\".\n",
    "\n",
    "# Step 1: Count how many instances of each class exist in the 'is_recid' column\n",
    "# count_0 = number of examples with is_recid == 0 (non-recidivists)\n",
    "# count_1 = number of examples with is_recid == 1 (recidivists)\n",
    "count_0, count_1 = None\n",
    "\n",
    "# Step 2: Create a new DataFrame containing only the non-recidivist samples (label 0)\n",
    "df_is_recid_0 = None\n",
    "\n",
    "# Step 3: Create another DataFrame containing only the recidivist samples (label 1)\n",
    "df_is_recid_1 = None\n",
    "\n",
    "# Step 4: Oversample the recidivist group (label 1) to match the size of the non-recidivist group (label 0)\n",
    "df_is_recid_1_over = None\n",
    "\n",
    "# Step 5: Concatenate the original non-recidivist group (label 0) and the oversampled recidivist group (label 1)\n",
    "# This creates a new balanced dataset where both classes have the same number of samples\n",
    "df_bal = None\n",
    "\n",
    "##############################################\n",
    "# Now let's visualize the balanced dataframe\n",
    "# No actions needed for the following three lines of code.\n",
    "print('Random over-sampling:')\n",
    "print(df_bal[\"is_recid\"].value_counts())\n",
    "df_bal[\"is_recid\"].value_counts().plot(kind='bar', title='Count (target)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6cf4b7-f435-405f-9d19-fbca6d936b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################\n",
    "# TODO: Complete this part\n",
    "##############################################\n",
    "\n",
    "# Split the balanced dataframe into features X and labels y \n",
    "# where X contains selected predictor columns, y contains the binary outcome 'is_recid'.\n",
    "X = None\n",
    "y = None\n",
    "\n",
    "# Now we split data into training and test dataset (80/20 split)\n",
    "X_train, X_test, y_train, y_test = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cbce379-4bdd-4e16-a885-eb5bbf04e72e",
   "metadata": {},
   "source": [
    "## Task 2 (10 points)\n",
    "TO DO:\n",
    "1. Data Preprocessing:\n",
    "   Some features, such as 'sex' and 'c_charge_degree', are categorical.\\\n",
    "   Others, such as 'age' and 'juv_misd_count', are numerical.\\\n",
    "   We need to convert categorical variables to numeric before we can use the data for our Machine Learnining models.\n",
    "   1. **(2 marks)** Numeric features: **scale to zero mean and unit variance**.\n",
    "   2. **(2 marks)** Categorical features: **Use one-hot encoding for categorical features**.\n",
    "3. Model training and evaluation:\n",
    "   1. **(3 marks)** Train a machine learning model for predicting recidivism with a machine learning algorithm discussed during the lectures **(Week 10 to Week 12)** (or any other appropriate algorithm not covered in the lectures). Which machine learning algorithm did you choose, and why? Report accuracy, confusion matrix. \n",
    "   2. **(3 marks)** Train an **artificial neural network (Multi-Layered Perceptron Classifier (MLP))** model for recidivism prediction. Report accuracy, and confusion matrix.\n",
    "  \n",
    "Confusion matrix:\n",
    "  \n",
    "|                  | **Predicted Positive** | **Predicted Negative** |\n",
    "|------------------|------------------------|------------------------|\n",
    "| **Actual Positive** | True Positive (TP)       | False Negative (FN)      |\n",
    "| **Actual Negative** | False Positive (FP)      | True Negative (TN)       |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5952a0-2769-4365-b738-90685fbdcf75",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################\n",
    "# TODO: Complete this part\n",
    "##############################################\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "# scale numerical variables to zero mean and unit variance for both traning and test dataset\n",
    "numeric_features = [] \n",
    "scaler = None\n",
    "X_train_num = None\n",
    "X_test_num  = None\n",
    "\n",
    "\n",
    "# Use one-hot encoding to encode categorical variables for both traning and test dataset\n",
    "categorical_features = []\n",
    "ohe = None\n",
    "X_train_cat = None\n",
    "X_test_cat  = None\n",
    "\n",
    "\n",
    "# Now we can combine numeric and categorical arrays\n",
    "# No actions needed for the following two lines of code.\n",
    "X_train_processed = np.hstack([X_train_num, X_train_cat])\n",
    "X_test_processed  = np.hstack([X_test_num,  X_test_cat])\n",
    "##############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f559c8b6-469d-4ff5-9a51-cd9dd74dfcc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################\n",
    "# TODO: Complete this part\n",
    "##############################################\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# Initialize and train the Logistic Regression model\n",
    "logsticRegression = None\n",
    "\n",
    "# Predictions\n",
    "y_pred = None\n",
    "\n",
    "# Report the results.\n",
    "print(\"Test accuracy: \", accuracy_score(y_test,y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc34d746-c7e7-47ff-a1f5-10c2715ed0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################\n",
    "# TODO: Complete this part\n",
    "##############################################\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# Initialize and train MLP model\n",
    "mlp_model = None\n",
    "\n",
    "# Predictions\n",
    "y_pred = None\n",
    "\n",
    "# Report the results.\n",
    "print(\"Test accuracy: \", accuracy_score(y_test,y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa9f37e-1505-48f6-92cd-8afdc4fd58b9",
   "metadata": {},
   "source": [
    "## Task 3 (10 points)\n",
    "1. **(2 marks)** For the neural network model, calculate False Positive Rate **by race**.\n",
    "\n",
    "    Confusion matrix:\n",
    "  \n",
    "|                  | **Predicted Positive** | **Predicted Negative** |\n",
    "|------------------|------------------------|------------------------|\n",
    "| **Actual Positive** | True Positive (TP)       | False Negative (FN)      |\n",
    "| **Actual Negative** | False Positive (FP)      | True Negative (TN)       |\n",
    "\n",
    "\n",
    "False Positive Rate (FPR) tells you how often negative instances (not recidivate) are incorrectly classified as positive (recidivate).\n",
    "Based on the confusion matrix, FPR is calculated as:\n",
    "\n",
    "<p style=\"text-align:center;\">False Positive Rate (FPR) = FP / (FP + TN)</p>\n",
    "\n",
    "2. **(8 marks)** Reflect on the disparities you observed in the assignment.\n",
    "    - Are there any differences in False Positive Rates between races?\n",
    "    - Are there potential sources of bias in the data?\n",
    "    - Describe what steps you would recommend for alleviating such bias in the intended classification model.\n",
    "    - Discuss the trade-offs and potential impacts of your chosen strategies on overall model performance and fairness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df814265-b092-4dba-a596-273800c2d6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################\n",
    "# TODO: Complete this part\n",
    "##############################################\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# To calculate FPR by race, first get the indices of each race category\n",
    "# Create a dictionary to store the list of row indices for each race category\n",
    "index_dict = {}\n",
    "\n",
    "# Reset indices of X_test and y_test so they align with indexing of y_pred\n",
    "# as X_test and y_test were split from a larger DataFrame (the original dataframe)\n",
    "X_test = X_test.reset_index(drop=True)\n",
    "y_test = y_test.reset_index(drop=True)\n",
    "\n",
    "# For each row in the test set, add its index to the corresponding race category\n",
    "for idx, race_category in X_test['race'].items():\n",
    "    if race_category in index_dict:\n",
    "        pass\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "\n",
    "# Compute FPR for each race group\n",
    "# Iterate over each race category\n",
    "all_fpr = []\n",
    "for race in index_dict.keys():\n",
    "    indices = index_dict[race]\n",
    "\n",
    "    # Count False Positives:\n",
    "    # These are the cases where the model predicted recidivism (1)\n",
    "    # but the actual label is non-recidivism (0)\n",
    "    num_false_positive = None\n",
    "    \n",
    "    # Count True Negatives:\n",
    "    # These are the cases where the model correctly predicted non-recidivism (0)\n",
    "    num_true_negative = None\n",
    "    \n",
    "    # Calculate False Positive Rate (FPR) based on the formula.\n",
    "    # FPR = FP / (FP + TN)\n",
    "    fpr = None\n",
    "\n",
    "    all_fpr.append(fpr)\n",
    "    print(f\"{race}: False Positive Rate (FPR)={fpr:.3f}\")\n",
    "\n",
    "\n",
    "# Visualization\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "races = index_dict.keys()\n",
    "plt.bar(races, all_fpr)\n",
    "plt.xlabel('Race')\n",
    "plt.ylabel('False Positive Rate')\n",
    "plt.title('False Positive Rate by Race')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e007ba1c-8f69-453a-a86d-7c05c79de28a",
   "metadata": {},
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
